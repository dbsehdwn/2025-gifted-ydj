{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzA87lqE6lDj"
      },
      "source": [
        "# GPT-2 모델 사용해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zS1qfUw6lDk",
        "outputId": "6ef9649a-cc73-4d62-ffb5-4fb94e6d4d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'a, and the first was to be given to all, at one-third of the value of those parts, as part of the rest; but it must be noted, that there might be some differences of this value. The fact was, that the'}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# 코드 한번에 보기\n",
        "from transformers import pipeline\n",
        "\n",
        "huggingface_model_name = \"gpt2\"\n",
        "pipe = pipeline(\"text-generation\", model=huggingface_model_name)\n",
        "pipe('a', max_new_tokens=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYkJVISK6lDk"
      },
      "source": [
        "### 생성 코드 더 자세히 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FTlaI076lDk",
        "outputId": "525fc083-7f9b-47a5-e511-777483829f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language model is a bit more complicated, but it's still pretty simple.\n",
            "\n",
            "The first thing you need to do is to create a new file called \"my_file.txt\". This file will contain the following:\n",
            "\n",
            "The name of the file.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "huggingface_model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name)\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(huggingface_model_name)\n",
        "\n",
        "input_text = \"The language model is\"\n",
        "encoded_input = tokenizer(input_text, return_tensors=\"pt\")\n",
        "output = model.generate(**encoded_input, max_new_tokens=50)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD-CmNqd6lDk"
      },
      "source": [
        "### 프롬프트 엔지니어링 체험해보기\n",
        "\n",
        "Can you make GPT-2 to summarize or translate?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in9rDlkt6lDk",
        "outputId": "6952e516-966b-455c-a001-77ab0a7d2572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " translate English to French :'hello'is 'Bonjour.' 'Thank you.'is 'Merci'  'Goodbye.'is 'Au revoir' 'Please.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au revoir.'is 'Au rev\n"
          ]
        }
      ],
      "source": [
        "prompt = \" translate English to French :'hello'is 'Bonjour.' 'Thank you.'is 'Merci'  'Goodbye.'is 'Au revoir' 'Please.'is\"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**encoded_input, max_new_tokens=200)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" Translate the following sentence from English to Spanish: 'Hi'\"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**encoded_input, max_new_tokens=200)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roDyM6TahUxA",
        "outputId": "d59c760c-7659-41d6-b4be-2529ede2d3eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Translate the following sentence from English to Spanish: 'Hi' means 'Hi' and 'Hi' means 'Hi'.\n",
            "\n",
            "'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi' and 'Hi' means 'Hi'. 'Hi' means 'Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" Translate 'hi' from English to Spanish\"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**encoded_input, max_new_tokens=200)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "athIhKBzhn2X",
        "outputId": "13f21e50-b1bd-41d7-80d7-9ed7f81e9c87"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Translate 'hi' from English to Spanish.\n",
            "\n",
            "The word 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of 'hi' and 'hi' is a contraction of '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" Question: Translate 'Hi' from English to Spanish  Answer: sure. In French, 'hi' is translated to French as\"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output=model.generate(\n",
        "    **encoded_input,\n",
        "    max_new_tokens=20,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    temperature=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "output = model.generate(**encoded_input, max_new_tokens=200)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMBJspEDhyun",
        "outputId": "334b8d87-7ef5-45f5-e1bf-0cbdfbcf2c66"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Question: Translate 'Hi' from English to Spanish  Answer: sure. In French, 'hi' is translated to French as 'Hi' and 's' to Spanish as 'Hi'. In Spanish, 's' is translated to Spanish as 'Hi' and 's' to Spanish as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to English as 'Hi'. In Spanish, 's' is translated to Spanish as 'Hi' and 's' to English as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to English as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to English as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to English as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to English as 'Hi'. In English, 'hi' is translated to English as 'Hi' and 's' to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" Question: Translate 'Hello' from English to French. Answer: Sure. In French, 'Hello' is translated as 'Bonjour'. / Question: Translate 'Thank you' from English to French. Answer: Sure. In French, 'Thank you' is translated as 'Merci'. /Question: Translate 'Goodbye' from English to French. Answer: Sure. In French, 'Goodbye' is translated as 'Au revoir'. /Question: Translate 'Please.' from English to French. Answer: Sure. In French, 'Please.' is translated as \"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output=model.generate(\n",
        "    **encoded_input,\n",
        "    max_new_tokens=20,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    temperature=0.7,\n",
        "    do_sample=True\n",
        ")\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-iL0snxkKN-",
        "outputId": "94207a33-62e8-4abd-af44-086db8feb45b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Question: Translate 'Hello' from English to French. Answer: Sure. In French, 'Hello' is translated as 'Bonjour'. / Question: Translate 'Thank you' from English to French. Answer: Sure. In French, 'Thank you' is translated as 'Merci'. /Question: Translate 'Goodbye' from English to French. Answer: Sure. In French, 'Goodbye' is translated as 'Au revoir'. /Question: Translate 'Please.' from English to French. Answer: Sure. In French, 'Please.' is translated as était à le toute. /Question: Translate 'Please come back.' from English to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \" Question: Translate 'Hi' from English to Spanish  Answer: sure. In French, 'hi' is translated to French as\"\n",
        "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output=model.generate(\n",
        "    **encoded_input,\n",
        "    max_new_tokens=20,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    temperature=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "output = model.generate(**encoded_input, max_new_tokens=200)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "o9dFXsq4vIzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}