앞쪽에 있던 단어들까지 다 저장해놓을 수 있는 순환모델에 대해 배웠다. 그걸 수치로 압축해놓으면 효율성이 많이 올라갔을 것 같다.gpt2언어모델을 사용해서 번역도 시도해보았다. 계속 시도를 해도 제대로 번역이잘 안되서 힘들었다. 그래도 대화형식으로 예시를 많이 나열해주니까 그나마 비슷하게 나왔던것 같다. 
