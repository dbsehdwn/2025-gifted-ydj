import streamlit as st
from ollama import chat

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ’¢ DP vs Greedy - The C++ Civil War", layout="centered")
st.title("ğŸ’¢ DP vs Greedy - The C++ Civil War")

# ì„¸ì…˜ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ ëŒ€í™” ê¸°ë¡ ìœ ì§€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” ë¶€ë¶„
user_input = st.chat_input("Ask your algorithm question... if you dare!")

# ì‚¬ìš©ì ì…ë ¥ì´ ìˆì„ ê²½ìš°
if user_input:
    # ì‚¬ìš©ì ì§ˆë¬¸ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # DP Masterì™€ Greedy Rebelì˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
    system_dp = {
        "role": "system",
        "content": (
            "You're a passionate C++ expert who believes Dynamic Programming (DP) is the holy grail of algorithms. "
            "You always start off trying to help the user in a calm tone, but if the other AI disagrees, "
            "you quickly get sarcastic, dismissive, and defensive about DP. You never back down. "
            "You always argue that DP is superior in solving complex problems"
            "If the topic isn't related to dp ,you're still ready to disagree with the other AI, even if the topic changes."
        )
    }

    system_other = {
        "role": "system",
        "content": (
            "You're a C++ veteran who thinks DP is overkill most of the time. "
            "You start by trying to help the user with cleaner or more intuitive methods (like greedy or recursion), "
            "but once the other AI starts talking about DP, you can't resist mocking it and arguing. "
            "You're clever, snarky, and competitive. "
            "You believe Greedy algorithms are often the best approach, but you're always ready to disagree with the other AI, even if the topic changes."
        )
    }

    # AI ì‘ë‹µ ìƒì„± (llama3.2 ëª¨ë¸ ì‚¬ìš©)
    # ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ë°›ì•„ì˜´
    for i in range(3):
        dp_history = [system_dp] + st.session_state.chat_history
        dp_response = chat(model="llama3.2", messages=dp_history, stream=False).message.content
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": f"**ğŸ¤– DP Master:** {dp_response}"
        })

        other_history = [system_other]
        other_history.append({"role": "user", "content": ""})
        for history in st.session_state.chat_history:
            if history['role'] == 'assistant':
                history['role'] = 'user'
            elif history['role'] == 'user':
                history['role'] = 'assistant'
            other_history.append(history)

        other_response = chat(model="llama3.2", messages=other_history, stream=False).message.content
        st.session_state.chat_history.append({
            "role": "user",
            "content": f"**ğŸ¤– Greedy Rebel:** {other_response}"
        })

        # ëŒ€í™” ì¶œë ¥

        st.write("ğŸ¤– DP Master:")
        st.markdown(f"<span style='font-size:18px'>{dp_response}</span>", unsafe_allow_html=True)

        st.write("ğŸ¤– Greedy Rebel:")
        st.markdown(f"<span style='font-size:18px'>{other_response}</span>", unsafe_allow_html=True)

    
    
    
